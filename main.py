#!/usr/bin/env python3
import sys
import json
import subprocess
import shutil
import os
import argparse
import platform
from datetime import datetime

# --- Vari√°vel Global para o Arquivo de Log ---
LOG_FILE = None

# --- Fun√ß√µes de Cores ---
C_RED = '\033[91m'
C_GREEN = '\033[92m'
C_YELLOW = '\033[93m'
C_BLUE = '\033[94m'
C_END = '\033[0m'

# --- Fun√ß√µes de Impress√£o Modificadas para Logging ---
def print_to_console_and_log(message, color=""):
    """Fun√ß√£o central que imprime na tela e opcionalmente no arquivo de log."""
    plain_message = message
    for code in [C_RED, C_GREEN, C_YELLOW, C_BLUE, C_END]:
        plain_message = plain_message.replace(code, "")
    
    print(f"{color}{message}{C_END}")
    
    if LOG_FILE:
        LOG_FILE.write(plain_message + "\n")
        LOG_FILE.flush()

def print_error(message):
    print_to_console_and_log(f"[ERRO] {message}", C_RED)

def print_info(message):
    print_to_console_and_log(f"[INFO] {message}", C_BLUE)

def print_success(message):
    print_to_console_and_log(f"[SUCESSO] {message}", C_GREEN)

# --- Fun√ß√µes de Setup e Verifica√ß√£o ---
def setup_logging(enable_log):
    """Configura o logging se a flag -l for passada."""
    if not enable_log: return
    global LOG_FILE
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    log_filename = os.path.join(log_dir, f"{timestamp}.log")
    try:
        LOG_FILE = open(log_filename, 'w', encoding='utf-8')
        print_info(f"Logging ativado. A sa√≠da ser√° salva em: {log_filename}")
    except IOError as e:
        print_error(f"N√£o foi poss√≠vel criar o arquivo de log: {e}")
        LOG_FILE = None

def check_dependencies(args):
    """Verifica as depend√™ncias com base nos argumentos fornecidos."""
    has_error = False
    if not shutil.which("yt-dlp"):
        print_error("Depend√™ncia n√£o encontrada: 'yt-dlp'. Instale-a.")
        has_error = True
    if not shutil.which("ffmpeg"):
        print_error("Depend√™ncia n√£o encontrada: 'ffmpeg'. Instale-a.")
        has_error = True

    if args.transcribe and not args.unified_mode:
        try: import whisper
        except ImportError:
            print_error("Depend√™ncia para transcri√ß√£o local n√£o encontrada: 'openai-whisper'. Use: pip install openai-whisper")
            has_error = True

    if args.context or args.unified_mode:
        try: import openai
        except ImportError:
            print_error("Depend√™ncia para a API OpenAI n√£o encontrada: 'openai'. Use: pip install openai")
            has_error = True
        if not os.getenv("OPENAI_API_TOKEN"):
            print_error("A vari√°vel de ambiente OPENAI_API_TOKEN n√£o est√° definida.")
            has_error = True
            
    return not has_error

def get_auth_details():
    """Obt√©m detalhes de autentica√ß√£o de VDL_TOKEN ou cookie.txt."""
    vdl_token = os.getenv("VDL_TOKEN")
    if vdl_token:
        print_info("Usando autentica√ß√£o via vari√°vel de ambiente VDL_TOKEN.")
        try:
            user_agent, cookie_value = vdl_token.split(';', 1)
            return user_agent, cookie_value
        except ValueError:
            print_error("Formato inv√°lido para VDL_TOKEN. Use 'user_agent;cookie_value'.")
            return None, None
    else:
        print_info("VDL_TOKEN n√£o encontrada. Tentando ler 'cookie.txt'.")
        try:
            with open("cookie.txt", 'r') as f: data = json.load(f)
            user_agent = data['userAgent']
            domain_key = list(data['.poseadfdc.grupoa.education'].keys())[0]
            cookie_value = data['.poseadfdc.grupoa.education'][domain_key]['aws-waf-token']['value']
            return user_agent, f"aws-waf-token={cookie_value}"
        except Exception as e:
            print_error(f"Falha ao processar o cookie.txt: {e}")
            return None, None

# --- Fun√ß√µes de Execu√ß√£o ---
def download_video(url, output_path, user_agent, cookie_header):
    print_info(f"Iniciando o download de: {url}")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    ffmpeg_path = shutil.which("ffmpeg")
    command = ["yt-dlp", "--user-agent", user_agent, "--add-header", f"Cookie: {cookie_header}", "--ffmpeg-location", ffmpeg_path, "--output", output_path, url]
    try:
        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', errors='replace', bufsize=1)
        for line in iter(process.stdout.readline, ''): print_to_console_and_log(line.strip())
        process.stdout.close()
        if process.wait() != 0:
            print_error("O download falhou.")
            return False
        print_success(f"Download conclu√≠do. V√≠deo salvo em: {output_path}")
        return True
    except Exception as e:
        print_error(f"Ocorreu um erro ao executar o yt-dlp: {e}")
        return False

def extract_audio(video_path):
    audio_path = os.path.splitext(video_path)[0] + ".mp3"
    print_info(f"Extraindo √°udio para: {audio_path}")
    command = ["ffmpeg", "-i", video_path, "-vn", "-q:a", "0", "-y", "-loglevel", "error", audio_path]
    try:
        subprocess.run(command, check=True)
        print_success(f"√Åudio extra√≠do com sucesso para: {audio_path}")
        return audio_path
    except subprocess.CalledProcessError as e:
        print_error(f"A extra√ß√£o de √°udio falhou: {e.stderr}")
        return None

# --- Fun√ß√µes de IA ---
def transcribe_audio_local(audio_path, model_name, use_gpu, output_dir):
    transcription_dir = os.path.join(output_dir, "transcriptions")
    os.makedirs(transcription_dir, exist_ok=True)
    transcription_path = os.path.join(transcription_dir, os.path.basename(os.path.splitext(audio_path)[0] + ".txt"))
    print_info(f"Iniciando a transcri√ß√£o LOCAL do √°udio para: {transcription_path}")
    try:
        import whisper, torch
        device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
        if use_gpu and not torch.cuda.is_available(): print_to_console_and_log("[AVISO] CUDA n√£o dispon√≠vel. Usando CPU.", C_YELLOW)
        model = whisper.load_model(model_name, device=device)
        result = model.transcribe(audio_path, fp16=False)
        with open(transcription_path, 'w', encoding='utf-8') as f: f.write(result["text"])
        print_success(f"Transcri√ß√£o local salva com sucesso em: {transcription_path}")
        return result["text"]
    except Exception as e:
        print_error(f"Ocorreu um erro durante a transcri√ß√£o local: {e}")
        return None

def generate_context_from_text(transcription_text, base_output_path, output_dir):
    context_dir = os.path.join(output_dir, "context")
    os.makedirs(context_dir, exist_ok=True)
    context_path = os.path.join(context_dir, os.path.basename(os.path.splitext(base_output_path)[0] + ".md"))
    print_info(f"Gerando conte√∫do aprofundado com a API da OpenAI. Salvando em: {context_path}")
    
    prompt = f"""
# MISS√ÉO

Sua miss√£o √© atuar como um especialista em design instrucional e editor de conte√∫do. Voc√™ deve transformar a transcri√ß√£o de uma aula em um material de estudo aprofundado e bem estruturado em formato Markdown. O resultado final deve ser t√£o completo que possa servir como o rascunho principal para um cap√≠tulo de e-book. O idioma de sa√≠da √© **Portugu√™s do Brasil**.

# CONTEXTO

A seguir est√° a transcri√ß√£o de uma aula ou palestra. O conte√∫do √© denso e cont√©m informa√ß√µes valiosas, incluindo conceitos t√©cnicos, exemplos pr√°ticos e insights do instrutor. √â crucial que todos os termos t√©cnicos, nomes de ferramentas, e jarg√µes espec√≠ficos da √°rea sejam preservados exatamente como foram ditos, sem tradu√ß√£o ou altera√ß√£o.

# INSTRU√á√ïES PASSO A PASSO (Pense como um especialista)

1.  **An√°lise Hol√≠stica:** Leia a transcri√ß√£o completa uma vez para entender o tema central, os objetivos de aprendizado impl√≠citos e a estrutura geral da aula.
2.  **Identifica√ß√£o de Pilares:** Identifique os 3 a 5 pilares de conhecimento ou t√≥picos principais que estruturam a aula.
3.  **Extra√ß√£o e Expans√£o:** Para cada pilar, extraia os conceitos-chave, defini√ß√µes, exemplos e argumentos. N√£o se limite a copiar; reestruture as frases para maior clareza e adicione pequenas expans√µes contextuais onde for apropriado para transformar a linguagem falada em uma prosa escrita de alta qualidade.
4.  **Estrutura√ß√£o do Documento:** Organize o material extra√≠do e expandido no formato Markdown detalhado abaixo. Seja met√≥dico e preencha cada se√ß√£o com conte√∫do relevante e profundo.

# FORMATO DE SA√çDA (Markdown)

## üìñ Resumo Executivo (Executive Summary)
Um par√°grafo conciso (3-5 frases) que resume o prop√≥sito da aula, os principais t√≥picos abordados e a principal conclus√£o ou habilidade ensinada.

## üéØ Objetivos de Aprendizagem
Com base no conte√∫do, liste de 3 a 5 objetivos de aprendizagem claros e mensur√°veis que um aluno alcan√ßaria ao estudar este material. Use o formato "Ao final deste cap√≠tulo, voc√™ ser√° capaz de:".

## üß† Contexto Aprofundado (In-depth Context)
Explique o "porqu√™" por tr√°s da aula. Onde este conhecimento se encaixa em um campo de estudo maior? Qual problema ele resolve? Por que √© importante para um profissional da √°rea? Elabore em 2-3 par√°grafos.

## üìö Detalhamento do Conte√∫do (Content Breakdown)
Este √© o n√∫cleo do documento. Para cada pilar de conhecimento identificado, crie uma subse√ß√£o.

### T√≥pico Principal 1: [Nome do T√≥pico]
   - **Defini√ß√£o/Conceito Central:** Explique o conceito principal em detalhes.
   - **Pontos-Chave (Bullet Points):** Liste os pontos mais importantes, argumentos e fatos relacionados a este t√≥pico em formato de lista.
   - **Exemplos Pr√°ticos e Analogias:** Descreva os exemplos ou analogias usados pelo instrutor para ilustrar o conceito. Se n√£o houver, crie um com base no conte√∫do.
   - **Conex√µes:** Como este t√≥pico se conecta com outros t√≥picos da aula ou com conhecimentos pr√©vios?

### T√≥pico Principal 2: [Nome do T√≥pico]
   - (Repita a estrutura acima)

### (Repita para todos os t√≥picos principais)

## ‚ú® Destaques (Highlights)
Em formato de lista, cite os 3 a 5 insights mais poderosos, dicas "pro" ou momentos "eureka" da aula. S√£o as "joias" do conte√∫do.

## ‚ö†Ô∏è Pontos de Aten√ß√£o (Lowlights / Common Pitfalls)
Em formato de lista, identifique os 2 a 3 pontos que podem ser fontes de confus√£o, erros comuns ou pr√©-requisitos que o aluno precisa dominar. O que pode dar errado se o conceito for mal aplicado?

## üîë Principais Li√ß√µes (Key Takeaways)
Liste de 3 a 5 conclus√µes ou li√ß√µes pr√°ticas que o aluno deve levar consigo ap√≥s estudar o material. Devem ser frases acion√°veis e f√°ceis de memorizar.

---
**TRANSCRI√á√ÉO BRUTA PARA AN√ÅLISE:**
---
{transcription_text}
"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv("OPENAI_API_TOKEN"))
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em design instrucional e editor de conte√∫do."},
                {"role": "user", "content": prompt}
            ]
        )
        context_markdown = response.choices[0].message.content
        with open(context_path, 'w', encoding='utf-8') as f: f.write(context_markdown)
        print_success(f"Contexto em Markdown salvo com sucesso em: {context_path}")
    except Exception as e:
        print_error(f"Falha ao gerar contexto com a API da OpenAI: {e}")

def transcribe_and_generate_context_via_api(audio_path, base_output_path, output_dir):
    print_info("Iniciando processo unificado com a API da OpenAI...")
    try:
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv("OPENAI_API_TOKEN"))
        print_info(f"Enviando √°udio '{audio_path}' para a API de transcri√ß√£o...")
        with open(audio_path, "rb") as audio_file:
            transcription_response = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
        transcription_text = transcription_response.text
        print_success("√Åudio transcrito com sucesso pela API.")
        
        transcription_dir = os.path.join(output_dir, "transcriptions")
        os.makedirs(transcription_dir, exist_ok=True)
        transcription_path = os.path.join(transcription_dir, os.path.basename(os.path.splitext(audio_path)[0] + ".txt"))
        with open(transcription_path, 'w', encoding='utf-8') as f: f.write(transcription_text)
        print_info(f"Transcri√ß√£o da API salva em: {transcription_path}")
        
        generate_context_from_text(transcription_text, base_output_path, output_dir)
    except Exception as e:
        print_error(f"Ocorreu um erro no processo unificado da API: {e}")

def main():
    """Fun√ß√£o principal do script."""
    parser = argparse.ArgumentParser(
        description="Baixa, transcreve e analisa v√≠deos.",
        formatter_class=argparse.RawTextHelpFormatter,
        epilog="""
Exemplos de uso:
  # Apenas baixar o v√≠deo e extrair o √°udio
  ./vdl "URL" "video.mp4"

  # Baixar e gerar a transcri√ß√£o LOCALMENTE com o modelo 'small'
  ./vdl "URL" "video.mp4" -t --whisper-model small

  # MODO UNIFICADO: Transcrever e gerar contexto via API da OpenAI
  ./vdl "URL" "video.mp4" -u
"""
    )
    parser.add_argument("url", nargs='?', default=None, help="A URL do v√≠deo.")
    parser.add_argument("filename", nargs='?', default=None, help="O nome do arquivo de v√≠deo de sa√≠da.")
    parser.add_argument("-d", "--directory", default="output_dir", help="Diret√≥rio de sa√≠da principal.")
    parser.add_argument("-l", "--log", action="store_true", help="Salva um log da opera√ß√£o.")
    parser.add_argument("-t", "--transcribe", action="store_true", help="Gera a transcri√ß√£o LOCALMENTE.")
    parser.add_argument("-c", "--context", action="store_true", help="Gera contexto via OpenAI a partir de transcri√ß√£o local.")
    parser.add_argument("-u", "--unified-mode", action="store_true", help="MODO UNIFICADO: Usa a API da OpenAI para transcrever e gerar contexto.")
    parser.add_argument("--gpu", action="store_true", help="Tenta usar a GPU para a transcri√ß√£o LOCAL.")
    parser.add_argument("--whisper-model", default="base", choices=['tiny', 'base', 'small', 'medium', 'large'], help="Modelo do Whisper para transcri√ß√£o LOCAL.")
    
    args = parser.parse_args()

    # Valida√ß√£o de argumentos mutuamente exclusivos
    if args.unified_mode and (args.transcribe or args.context):
        parser.error("O argumento -u (modo unificado) n√£o pode ser usado em conjunto com -t (transcri√ß√£o local) ou -c (contexto local).")

    if not args.transcribe and (args.gpu or args.whisper_model != 'base'):
        parser.error("Os argumentos --gpu e --whisper-model s√≥ podem ser usados em conjunto com -t (transcri√ß√£o local).")

    # L√≥gica de depend√™ncia: -c implica -t
    if args.context:
        args.transcribe = True

    setup_logging(args.log)

    if not args.url or not args.filename:
        parser.print_help()
        sys.exit(1)

    if not check_dependencies(args):
        sys.exit(1)

    user_agent, cookie = get_auth_details()
    if not all([user_agent, cookie]):
        sys.exit(1)

    video_output_path = os.path.join(args.directory, args.filename)
    
    if download_video(args.url, video_output_path, user_agent, cookie):
        audio_path = extract_audio(video_output_path)
        if not audio_path: sys.exit(1)

        if args.unified_mode:
            transcribe_and_generate_context_via_api(audio_path, video_output_path, args.directory)
        elif args.transcribe:
            transcription_text = transcribe_audio_local(audio_path, args.whisper_model, args.gpu, args.directory)
            if transcription_text and args.context:
                generate_context_from_text(transcription_text, video_output_path, args.directory)

    if LOG_FILE: LOG_FILE.close()

if __name__ == "__main__":
    main()
